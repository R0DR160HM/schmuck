# ğŸ‡§ğŸ‡· Hunsrik Language RAG Translation System

Sistema RAG (Retrieval-Augmented Generation) avanÃ§ado para traduÃ§Ã£o PortuguÃªs â†’ Hunsriqueano usando Gemma 3, com busca hÃ­brida inteligente e extraÃ§Ã£o contextual.

## ğŸ“š O Que Este Sistema Faz

- **Processa mÃºltiplos tipos de recursos**:
  - ğŸ“– DicionÃ¡rios PortuguÃªs-Hunsrik
  - ğŸ“ Regras gramaticais
  - ğŸ“° Textos de exemplo (Hunsrickisch Wikipedia)
- **Chunking inteligente** adaptado por tipo de recurso
- **Busca hÃ­brida em 3 fases**:
  1. Busca no dicionÃ¡rio com boost de palavras-chave
  2. ExtraÃ§Ã£o automÃ¡tica de termos hunsriqueano
  3. Busca contextual em textos reais
- **TraduÃ§Ã£o com contexto dinÃ¢mico** usando Gemma 3
- **Logging completo** de todas as traduÃ§Ãµes

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

Certifique-se de ter o Ollama instalado e os modelos baixados:

```bash
# Verificar se Ollama estÃ¡ instalado
ollama --version

# Baixar os modelos necessÃ¡rios
ollama pull gemma3n:e2b # VocÃª pode mudar para um modelo maior alterando o `GEN_MODEL` dentro de `schmuck.py`, mas o uso de modelos MENORES Ã© contra-indicado
ollama pull embeddinggemma
```

### 2. Instalar DependÃªncias Python

```bash
pip install -r requirements.txt
```

### 3. Organizar os Recursos

Organize seus arquivos na pasta `resources/`:

```
resources/
â”œâ”€â”€ dicts/          # DicionÃ¡rios PT-HRX (PDFs ou TXTs)
â””â”€â”€ samples/        # Textos em Hunsrik (ex: artigos Wikipedia)
```

### 4. Executar o Sistema

```bash
python schmuck.py
```

Na primeira execuÃ§Ã£o:
1. âœ… Extrai texto de todos os PDFs e TXTs
2. âœ… Cria chunks inteligentes por tipo de recurso
3. âœ… Gera embeddings com `embeddinggemma`
4. âœ… Salva vector store em `hunsrik_vectors.json`
5. âœ… Inicia modo interativo

## ğŸ’¬ Exemplo de Uso (dados inventados)

```
You: Eu tenho um cachorro grande

ğŸ” Fase 1: Buscando no dicionÃ¡rio...
   âœ“ 15 entradas do dicionÃ¡rio
   [1] Score: 0.876 | cachorro â†’ Hund [substantivo masculino]...
   [2] Score: 0.734 | ter â†’ hon, hawwe [verbo]...
   [3] Score: 0.621 | grande â†’ groos, grooss [adjetivo]...

   ğŸ¯ Termos Hunsrik extraÃ­dos: hund, hon, groos, en, ich

ğŸ” Fase 2: Buscando exemplos em textos Hunsrik...
   âœ“ 8 exemplos de uso encontrados
   [1] Ich hon en groosse Hund. De Hund is sehr freindlich...
   [2] Mein Vadder hot en Hund unn en Katz...

ğŸ¤– Gerando traduÃ§Ã£o com gemma3n:e2b...

ğŸ¤– Answer:
Ich hon en groose Hund
```

## ğŸ“ Comandos

- Digite qualquer frase em portuguÃªs para traduzir
- `reprocess` - Recarregar e reprocessar todos os recursos
- `quit` ou `exit` - Sair do programa

## ğŸ”§ ConfiguraÃ§Ã£o

Edite a seÃ§Ã£o de configuraÃ§Ã£o em `schmuck.py`:

```python
# ---------- CONFIG ----------
EMBED_MODEL = "embeddinggemma"    # Modelo de embeddings
GEN_MODEL = "gemma3n:e2b"         # Modelo de geraÃ§Ã£o
CHUNK_SIZE = 300                  # Caracteres por chunk
CHUNK_OVERLAP = 120               # Overlap entre chunks
TOP_K_DICT = 20                   # Chunks do dicionÃ¡rio (dinÃ¢mico)
TOP_K_SAMPLES = 8                 # Chunks de exemplos
LOG_FILE = "translation_log.jsonl" # Log de traduÃ§Ãµes
# ----------------------------
```

## ğŸ§  Arquitetura do Sistema

### **Fase 1: VetorizaÃ§Ã£o (IndexaÃ§Ã£o)**

```
ğŸ“‚ resources/
    â”œâ”€â”€ dicts/     â†’ Chunking por entrada de dicionÃ¡rio
    â””â”€â”€ samples/   â†’ Chunking por caracteres (300 chars)
         â†“
    [Limpeza de metadados]
         â†“
    [GeraÃ§Ã£o de embeddings com embeddinggemma]
         â†“
    ğŸ’¾ hunsrik_vectors.json
```

### **Fase 2: Busca HÃ­brida (3 Etapas)**

```
Input: "Eu tenho um cachorro"
    â†“
[ETAPA 1] Busca no DicionÃ¡rio
    â”œâ”€ Query variations: ["eu", "tenho", "cachorro", "eu hunsrik"...]
    â”œâ”€ Keyword boost: +50% se palavra exata encontrada
    â”œâ”€ Match count: prioriza chunks com mÃºltiplas palavras
    â””â”€ Resultado: TOP 20 chunks (dinÃ¢mico por tamanho da frase)
    â†“
[ETAPA 2] ExtraÃ§Ã£o de Termos Hunsrik
    â”œâ”€ MÃ©todo 1: AnÃ¡lise de setas (â†’)
    â”‚   â”œâ”€ Se tem seta: todas palavras Ã  direita
    â”‚   â””â”€ Se nÃ£o: primeira palavra
    â”œâ”€ MÃ©todo 2: CaracterÃ­sticas linguÃ­sticas (scoring)
    â”‚   â”œâ”€ Vogais duplas (aa, ee, oo): +2 pontos
    â”‚   â”œâ”€ Umlauts (Ã¤, Ã«, Ã¯, Ã¶, Ã¼): +3 pontos
    â”‚   â”œâ”€ PadrÃµes germÃ¢nicos (ge-, ver-, fer-): +1 ponto
    â”‚   â””â”€ Filtro de stopwords portuguesas
    â””â”€ Resultado: ["hund", "hon", "ich", "en", "groos"]
    â†“
[ETAPA 3] Busca em Samples
    â”œâ”€ Busca com termos extraÃ­dos
    â”œâ”€ Boost: +20% se mesmo sample tem mÃºltiplos termos
    â””â”€ Resultado: TOP 8 textos de exemplo
    â†“
[GERAÃ‡ÃƒO] Prompt DinÃ¢mico
    â”œâ”€ Contexto do dicionÃ¡rio (20 chunks)
    â”œâ”€ Exemplos reais extraÃ­dos dos samples
    â””â”€ Gemma 3 gera traduÃ§Ã£o (temp=0.15)
```

## ğŸ¯ Diferenciais TÃ©cnicos

### **1. Chunking Inteligente**
- **DicionÃ¡rios**: Detecta entradas por regex, mantÃ©m estrutura completa
- **Samples**: Chunking por caracteres com overlap proporcional

### **2. Limpeza de Metadados**
- **Converte** categorias gramaticais: `sm` â†’ `[substantivo masculino]`
- **Remove** ruÃ­do: transcriÃ§Ãµes fonÃ©ticas, etimologias, marcadores de domÃ­nio

### **3. Busca com Keyword Boost**
- +50% de score para chunks com palavra exata
- Reduz falsos positivos temÃ¡ticos

### **4. AgregaÃ§Ã£o por Match Count**
- Prioriza chunks que aparecem em mÃºltiplas queries
- Identifica traduÃ§Ãµes mais relevantes automaticamente

### **5. ExtraÃ§Ã£o de Termos com Scoring**
- Sistema de pontuaÃ§Ã£o multicritÃ©rio
- Filtra palavras portuguesas automaticamente
- Extrai de **TODOS** os resultados do dicionÃ¡rio

### **6. Fallback Inteligente**
- Se nÃ£o encontrar termos Hunsrik, usa palavras originais
- Garante que sempre haverÃ¡ contexto de samples

### **7. Exemplos DinÃ¢micos**
- Extrai frases reais dos samples encontrados
- Adapta ao contexto da consulta especÃ­fica

### **8. Logging Completo**
- Salva todas traduÃ§Ãµes em `translation_log.jsonl`
- Inclui: input, output, chunks usados, termos extraÃ­dos, scores

## ğŸ“‚ Estrutura do Projeto

```
schmuck/
â”œâ”€â”€ schmuck.py                  # Sistema RAG principal
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ README.md                   # Esta documentaÃ§Ã£o
â”œâ”€â”€ FOLDER_STRUCTURE.md         # Estrutura detalhada
â”œâ”€â”€ hunsrik_vectors.json        # Vector store (gerado automaticamente)
â”œâ”€â”€ translation_log.jsonl       # Log de traduÃ§Ãµes (gerado automaticamente)
â””â”€â”€ resources/                  # Seus materiais Hunsrik
    â”œâ”€â”€ dicts/                  # DicionÃ¡rios PT-HRX
    â””â”€â”€ samples/                # Textos de exemplo (Wikipedia, etc)
        â”œâ”€â”€ WIKI - Hunsrickisch Sproch.txt
        â”œâ”€â”€ WIKI - Brasil.txt
        â””â”€â”€ ...
```

## ğŸ¯ Por Que RAG em Vez de Fine-Tuning?

Para lÃ­nguas de baixo recurso como Hunsrik, RAG Ã© superior:

| CritÃ©rio | RAG âœ… | Fine-Tuning âŒ |
|----------|--------|----------------|
| **Dados necessÃ¡rios** | Poucos documentos | Milhares de pares PT-HRX |
| **AtualizaÃ§Ã£o** | Adicionar PDF e reprocessar | Retreinar modelo completo |
| **PreservaÃ§Ã£o** | Estrutura original intacta | Perde nuances de entrada |
| **Recursos** | CPU suficiente | GPU de alto desempenho |
| **Tempo** | Minutos para indexar | Horas/dias para treinar |
| **Rastreabilidade** | Sabe de onde veio a info | Caixa preta |
| **Custo** | Quase zero | Alto (GPU cloud) |

## ğŸ”® Melhorias Futuras

- [ ] **OCR integrado** para PDFs escaneados
- [ ] **Cache de embeddings** por arquivo para updates incrementais
- [ ] **Interface web** com Gradio/Streamlit
- [ ] **Suporte a voz** (speech-to-text PT â†’ traduÃ§Ã£o â†’ text-to-speech HRX)
- [ ] **Fine-tuning hÃ­brido**: RAG para dicionÃ¡rio + modelo fino-tunado para conversaÃ§Ã£o
- [ ] **Multi-direcional**: Hunsrik â†’ PortuguÃªs
- [ ] **MÃ©tricas de qualidade**: BLEU score, avaliaÃ§Ã£o humana

## ğŸ› Troubleshooting

| Problema | SoluÃ§Ã£o |
|----------|---------|
| `Error: bad character range` | JÃ¡ corrigido no cÃ³digo (regex das setas) |
| `No embeddings generated` | Verifique se Ollama estÃ¡ rodando: `ollama serve` |
| `Model not found` | Baixe os modelos: `ollama pull gemma3n:e2b` |
| `PDF extraction fails` | PDF pode ser imagem. Use OCR ou converta para TXT |
| `Empty dictionary results` | Verifique se arquivos estÃ£o em `resources/dicts/` |
| `Slow on first run` | Normal. Embeddings sÃ£o gerados uma vez e salvos |

## ğŸ“Š Performance

Testado com:
- **DicionÃ¡rios**: ~3,000 entradas
- **Samples**: ~100 artigos Wikipedia Hunsrik
- **Vector store**: ~15,000 chunks
- **Tempo de indexaÃ§Ã£o**: ~10-15 minutos (primeira vez)
- **Tempo de query**: ~2-4 segundos por traduÃ§Ã£o
- **Uso de RAM**: ~2-3 GB

## ğŸ¤ Contribuindo

Este Ã© um projeto pessoal, mas sugestÃµes sÃ£o bem-vindas! Abra uma issue ou PR.

## ğŸ“„ LicenÃ§a

MIT License - Use como quiser!
